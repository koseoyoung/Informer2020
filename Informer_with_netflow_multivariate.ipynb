{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IM6CZzW_CH0"
      },
      "source": [
        "# Informer Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdaIHYx4_ECL"
      },
      "source": [
        "## Download code and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA_i2gbl-rn-",
        "outputId": "4f6b4a5c-dfa1-439c-d8dd-625e4e2c3f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Informer2020'...\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/koseoyoung/Informer2020.git\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5GFng7v7Eq0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "if not 'Informer2020' in sys.path:\n",
        "    sys.path += ['Informer2020']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YW9TS6jp_YXc"
      },
      "outputs": [],
      "source": [
        "# !pip install -r ./Informer2020/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm7kFeYkffoH"
      },
      "source": [
        "## Experiments: Train and Test (urg16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqQBJWHeMzP-"
      },
      "outputs": [],
      "source": [
        "from data.data_loader import Dataset_Custom\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "from utils.tools import dotdict\n",
        "from exp.exp_informer import Exp_Informer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bFrfuw6Oxpi"
      },
      "outputs": [],
      "source": [
        "args = dotdict()\n",
        "\n",
        "# custom data: xxx.csv\n",
        "# data features: ['date', ...(other features), target feature]\n",
        "\n",
        "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
        "\n",
        "args.data = 'custom' # data\n",
        "args.root_path = './Informer2020/'\n",
        "args.data_path = 'updated_urg16.csv'\n",
        "args.features = 'M' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
        "args.target = 'td'\n",
        "args.freq = 's'\n",
        "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
        "\n",
        "args.seq_len = 96 # input sequence length of Informer encoder\n",
        "args.label_len = 48 # start token length of Informer decoder\n",
        "args.pred_len = 24 # prediction sequence length\n",
        "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
        "\n",
        "args.enc_in = 7 # encoder input size\n",
        "args.dec_in = 7 # decoder input size\n",
        "args.c_out = 7 # output size\n",
        "args.factor = 5 # probsparse attn factor\n",
        "args.d_model = 512 # dimension of model\n",
        "args.n_heads = 8 # num of heads\n",
        "args.e_layers = 2 # num of encoder layers\n",
        "args.d_layers = 1 # num of decoder layers\n",
        "args.d_ff = 2048 # dimension of fcn in model\n",
        "args.dropout = 0.05 # dropout\n",
        "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
        "args.embed = 'timeF' # time features encoding, options:[timeF, fixed, learned]\n",
        "args.activation = 'gelu' # activation\n",
        "args.distil = True # whether to use distilling in encoder\n",
        "args.output_attention = False # whether to output attention in ecoder\n",
        "args.mix = True\n",
        "args.padding = 0\n",
        "args.freq = 'h'\n",
        "\n",
        "args.batch_size = 32 \n",
        "args.learning_rate = 0.0001\n",
        "args.loss = 'mse'\n",
        "args.lradj = 'type1'\n",
        "args.use_amp = False # whether to use automatic mixed precision training\n",
        "\n",
        "args.num_workers = 0\n",
        "args.itr = 1\n",
        "args.train_epochs = 6\n",
        "args.patience = 3\n",
        "args.des = 'exp'\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() else False\n",
        "args.gpu = 0\n",
        "\n",
        "args.use_multi_gpu = False\n",
        "args.devices = '0,1,2,3'\n",
        "\n",
        "Data = Dataset_Custom\n",
        "timeenc = 0 if args.embed!='timeF' else 1\n",
        "flag = 'test'; shuffle_flag = False; drop_last = True; batch_size = 1\n",
        "\n",
        "data_set = Data(\n",
        "    root_path=args.root_path,\n",
        "    data_path=args.data_path,\n",
        "    flag=flag,\n",
        "    size=[args.seq_len, args.label_len, args.pred_len],\n",
        "    features=args.features,\n",
        "    timeenc=timeenc,\n",
        "    target=args.target, # HULL here\n",
        "    freq=args.freq # 'h': hourly, 't':minutely\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    data_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=shuffle_flag,\n",
        "    num_workers=args.num_workers,\n",
        "    drop_last=drop_last)\n",
        "     \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0--9JC0eO_WT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.path.join(args.root_path, args.data_path))\n",
        "\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkNDT2jMPCUf"
      },
      "outputs": [],
      "source": [
        "batch_x,batch_y,batch_x_mark,batch_y_mark = data_set[0]\n",
        "print (batch_x.shape)\n",
        "print (batch_y.shape)\n",
        "print (batch_x_mark.shape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoWS2rnZ7lwc"
      },
      "source": [
        "args.detail_freq = args.freq\n",
        "args.freq = args.freq[-1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUcvSLlkSFTx"
      },
      "outputs": [],
      "source": [
        "print(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1jr1qA1LGI4"
      },
      "outputs": [],
      "source": [
        "Exp = Exp_Informer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbWsSmc8LKes"
      },
      "outputs": [],
      "source": [
        "for ii in range(args.itr):\n",
        "    # setting record of experiments\n",
        "    setting = '{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_nh{}_el{}_dl{}_df{}_at{}_fc{}_eb{}_dt{}_mx{}_{}_{}'.format(args.model, args.data, args.features, \n",
        "                args.seq_len, args.label_len, args.pred_len,\n",
        "                args.d_model, args.n_heads, args.e_layers, args.d_layers, args.d_ff, args.attn, args.factor, args.embed, args.distil, args.mix, args.des, ii)\n",
        "\n",
        "    # set experiments\n",
        "    exp = Exp(args)\n",
        "    \n",
        "    # train\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)\n",
        "    \n",
        "    # test\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting)\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL7S-7JvgEtR"
      },
      "source": [
        "## Predict (urg16) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0YI1zx6ACiz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# set saved model path\n",
        "setting = 'informer_custom_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0'\n",
        "# setting = 'informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_mxTrue_exp_0'\n",
        "\n",
        "# path = os.path.join(args.checkpoints,setting,'checkpoint.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTkluNNcyMJt"
      },
      "outputs": [],
      "source": [
        "# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n",
        "# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n",
        "# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n",
        "exp = Exp(args)\n",
        "exp.predict(setting, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBCPbjGuzAZb"
      },
      "outputs": [],
      "source": [
        "# the prediction will be saved in ./results/{setting}/real_prediction.npy\n",
        "import numpy as np\n",
        "\n",
        "prediction = np.load('./results/'+setting+'/real_prediction.npy')\n",
        "\n",
        "prediction.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yFuVkTV30_j"
      },
      "source": [
        "### More details about Prediction - prediction function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sv9AR_Aw030r"
      },
      "outputs": [],
      "source": [
        "# here is the detailed code of function predict\n",
        "\n",
        "def predict(exp, setting, load=False):\n",
        "    pred_data, pred_loader = exp._get_data(flag='pred')\n",
        "        \n",
        "    if load:\n",
        "        path = os.path.join(exp.args.checkpoints, setting)\n",
        "        best_model_path = path+'/'+'checkpoint.pth'\n",
        "        exp.model.load_state_dict(torch.load(best_model_path))\n",
        "\n",
        "    exp.model.eval()\n",
        "        \n",
        "    preds = []\n",
        "        \n",
        "    for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(pred_loader):\n",
        "        batch_x = batch_x.float().to(exp.device)\n",
        "        batch_y = batch_y.float()\n",
        "        batch_x_mark = batch_x_mark.float().to(exp.device)\n",
        "        batch_y_mark = batch_y_mark.float().to(exp.device)\n",
        "\n",
        "        # decoder input\n",
        "        if exp.args.padding==0:\n",
        "            dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
        "        elif exp.args.padding==1:\n",
        "            dec_inp = torch.ones([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
        "        else:\n",
        "            dec_inp = torch.zeros([batch_y.shape[0], exp.args.pred_len, batch_y.shape[-1]]).float()\n",
        "        dec_inp = torch.cat([batch_y[:,:exp.args.label_len,:], dec_inp], dim=1).float().to(exp.device)\n",
        "        # encoder - decoder\n",
        "        if exp.args.use_amp:\n",
        "            with torch.cuda.amp.autocast():\n",
        "                if exp.args.output_attention:\n",
        "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "                else:\n",
        "                    outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "        else:\n",
        "            if exp.args.output_attention:\n",
        "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
        "            else:\n",
        "                outputs = exp.model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
        "        f_dim = -1 if exp.args.features=='MS' else 0\n",
        "        batch_y = batch_y[:,-exp.args.pred_len:,f_dim:].to(exp.device)\n",
        "        \n",
        "        pred = outputs.detach().cpu().numpy()#.squeeze()\n",
        "        \n",
        "        preds.append(pred)\n",
        "\n",
        "    preds = np.array(preds)\n",
        "    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
        "    \n",
        "    # result save\n",
        "    folder_path = './results/' + setting +'/'\n",
        "    if not os.path.exists(folder_path):\n",
        "        os.makedirs(folder_path)\n",
        "    \n",
        "    np.save(folder_path+'real_prediction.npy', preds)\n",
        "    \n",
        "    return preds\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVLWZL2a1pwB"
      },
      "outputs": [],
      "source": [
        "# you can also use this prediction function to get result\n",
        "prediction = predict(exp, setting, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwtZmQC71uc8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(prediction[0,:,-1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnePVyrW4I14"
      },
      "source": [
        "### More details about Prediction - prediction dataset\n",
        "\n",
        "You can give a `root_path` and `data_path` of the data you want to forecast, and set `seq_len`, `label_len`, `pred_len` and other arguments as other Dataset. The difference is that you can set a more detailed freq such as `15min` or `3h` to generate the timestamp of prediction series.\n",
        "\n",
        "`Dataset_Pred` only has one sample (including `encoder_input: [1, seq_len, dim]`, `decoder_token: [1, label_len, dim]`, `encoder_input_timestamp: [1, seq_len, date_dim]`, `decoder_input_timstamp: [1, label_len+pred_len, date_dim]`). It will intercept the last sequence of the given data (seq_len data) to forecast the unseen future sequence (pred_len data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpXhNGp34Hf4"
      },
      "outputs": [],
      "source": [
        "from data.data_loader import Dataset_Pred\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Rpd1q74T8N"
      },
      "outputs": [],
      "source": [
        "Data = Dataset_Pred\n",
        "timeenc = 0 if args.embed!='timeF' else 1\n",
        "flag = 'pred'; shuffle_flag = False; drop_last = False; batch_size = 1\n",
        "\n",
        "freq = 's'\n",
        "print(freq)\n",
        "\n",
        "data_set = Data(\n",
        "    root_path=args.root_path,\n",
        "    data_path=args.data_path,\n",
        "    flag=flag,\n",
        "    size=[args.seq_len, args.label_len, args.pred_len],\n",
        "    features=args.features,\n",
        "    target=args.target,\n",
        "    timeenc=timeenc,\n",
        "    freq=freq\n",
        ")\n",
        "data_loader = DataLoader(\n",
        "    data_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=shuffle_flag,\n",
        "    num_workers=args.num_workers,\n",
        "    drop_last=drop_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42C84BfY6UPV"
      },
      "outputs": [],
      "source": [
        "len(data_set), len(data_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNhEP_7sAgqC"
      },
      "source": [
        "## Visualization (urg16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMRk8VkQ2Iko"
      },
      "outputs": [],
      "source": [
        "# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n",
        "# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n",
        "\n",
        "preds = np.load('./results/'+setting+'/pred.npy')\n",
        "trues = np.load('./results/'+setting+'/true.npy')\n",
        "\n",
        "# [samples, pred_len, dimensions]\n",
        "preds.shape, trues.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEGhDOmxAeAb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyPuOPGAAjl3"
      },
      "outputs": [],
      "source": [
        "# draw td prediction\n",
        "plt.figure()\n",
        "plt.plot(trues[0,:,-1], label='GroundTruth')\n",
        "plt.plot(preds[0,:,-1], label='Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXe7Nkr-P__P"
      },
      "outputs": [],
      "source": [
        "# draw dstip prediction\n",
        "plt.figure()\n",
        "plt.plot(trues[0,:,0], label='GroundTruth')\n",
        "plt.plot(preds[0,:,0], label='Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}